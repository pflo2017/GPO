# GPO Project

Run the application with:

```bash
python run_gpo.py cloud   # Run cloud dashboard
python run_gpo.py local   # Run local brain
```
# GPO - AI-Powered Project Orchestrator

An intelligent project orchestration system designed specifically for Language Service Providers (LSPs) to proactively identify and mitigate risks in translation projects using advanced AI capabilities.

## ğŸ¯ Overview

GPO (Project Orchestrator) acts as an intelligent co-pilot for Project Managers in LSPs, providing:

- **AI-Powered Risk Assessment**: Real-time analysis using Large Language Models (Gemini)
- **Document Intelligence**: Advanced parsing and analysis of DOCX, PDF, and TXT files
- **Proactive Recommendations**: Actionable insights to mitigate identified risks
- **Sensitive Data Detection**: Automatic identification of PHI, PII, and confidential information
- **Seamless Integration**: API-first module that integrates with existing Translation Management Systems
- **Professional UI**: Clean, intuitive web interface for project management

## ğŸš€ Key Features

### Core Functionality
- **Real-time AI Risk Assessment**: Analyzes projects using LLM for multiple risk factors
- **Intelligent Document Analysis**: Parses and analyzes complex documents for content understanding
- **Sensitive Content Detection**: Identifies medical, legal, and technical content requiring specialized expertise
- **Predictive Deadline Management**: Analyzes time remaining vs. progress with AI insights
- **Resource Optimization**: Evaluates workload and capacity with intelligent recommendations
- **Quality Assurance**: Considers content type and linguist expertise for optimal assignments

### AI Capabilities
- **Document Complexity Scoring**: AI-powered analysis of document readability and technical complexity
- **Terminology Identification**: Automatic detection of specialized terms and jargon
- **Risk Prioritization**: Intelligent ranking of risks (Sensitive Data > Deadline > Quality > Resource)
- **Contextual Recommendations**: AI-generated actionable advice based on project context

## ğŸ› ï¸ Technology Stack

- **Backend**: Flask (Python 3.10+)
- **Database**: Supabase (PostgreSQL)
- **ORM**: SQLAlchemy
- **AI/ML**: Google Gemini (Large Language Model)
- **Document Processing**: python-docx, PyMuPDF
- **Frontend**: HTML + Tailwind CSS
- **Production**: Docker, Gunicorn
- **Data Generation**: Faker
- **Environment**: python-dotenv

## ğŸ“‹ Prerequisites

- Python 3.10+
- Docker (for production deployment)
- Supabase account
- Google Gemini API key
- Git

## ğŸš€ Quick Start

### Option 1: Docker Deployment (Recommended)

```bash
# Clone the repository
git clone <repository-url>
cd gpo_product

# Build Docker image
docker build -t gpo-product .

# Run with environment variables
docker run -p 5000:5000 \
  -e SUPABASE_URL='your_supabase_url' \
  -e SUPABASE_PASSWORD='your_supabase_password' \
  -e SECRET_KEY='your_secret_key' \
  -e LLM_API_KEY='your_gemini_api_key' \
  gpo-product
```

### Option 2: Local Development

```bash
# Navigate to project directory
cd gpo_product

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export SUPABASE_URL='your_supabase_url'
export SUPABASE_PASSWORD='your_supabase_password'
export SECRET_KEY='your_secret_key'
export LLM_API_KEY='your_gemini_api_key'

# Run the application
python app.py
```

The application will be available at `http://localhost:5000`

## ğŸ—„ï¸ Database Setup

1. Create a Supabase project at https://supabase.com/
2. Run the following SQL commands in your Supabase SQL Editor:

```sql
-- Create linguists table
CREATE TABLE linguists (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    name TEXT NOT NULL,
    languages TEXT NOT NULL,
    specialties TEXT NOT NULL,
    speed_score INTEGER NOT NULL,
    quality_score INTEGER NOT NULL,
    current_load TEXT NOT NULL
);

-- Create projects table
CREATE TABLE projects (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    client_name TEXT NOT NULL,
    project_name TEXT NOT NULL,
    language_pair TEXT NOT NULL,
    content_type TEXT NOT NULL,
    start_date DATE NOT NULL,
    due_date DATE NOT NULL,
    initial_word_count INTEGER NOT NULL,
    translated_words INTEGER NOT NULL,
    assigned_linguist_id BIGINT,
    status TEXT NOT NULL,
    gpo_risk_status TEXT,
    gpo_risk_reason TEXT,
    gpo_recommendation TEXT,
    source_file_path TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Disable RLS for both tables
ALTER TABLE linguists DISABLE ROW LEVEL SECURITY;
ALTER TABLE projects DISABLE ROW LEVEL SECURITY;
```

## ğŸ“Š Usage Guide

### 1. Generate Sample Data
- Visit the home page
- Click "Generate Dummy Data" to populate the database with sample projects and linguists
- This creates 15 linguists and 25 projects with realistic data

### 2. Create New Project
- Navigate to "Create Project" from the dashboard
- Fill in project details (client, name, language pair, content type, due date, word count)
- Upload a source document (DOCX, PDF, or TXT)
- The AI will automatically analyze the document and provide risk assessment

### 3. View AI Analysis
- The system automatically performs AI analysis on uploaded documents
- View risk status, detailed reasoning, and actionable recommendations
- Run additional analysis on existing projects using the "Run GPO Analysis" button

### 4. Understanding Risk Levels
- **Critical Risk**: Sensitive data detected, immediate action required
- **High Risk**: Multiple risk factors detected, urgent attention needed
- **Medium Risk**: Some concerns identified, monitoring recommended
- **Low Risk**: Minor issues detected, standard procedures sufficient
- **On Track**: No significant risks identified

## ğŸ”§ Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `SUPABASE_URL` | Your Supabase project URL | Yes |
| `SUPABASE_PASSWORD` | Database password | Yes |
| `SECRET_KEY` | Flask secret key | Yes |
| `LLM_API_KEY` | Google Gemini API key | Yes |
| `FLASK_ENV` | Environment (production/development) | No |
| `SUPABASE_HOST` | Database host (default: auto) | No |
| `SUPABASE_PORT` | Database port (default: 6543) | No |

## ğŸ“ Project Structure

```
gpo_product/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Dockerfile            # Docker configuration
â”œâ”€â”€ start.sh              # Production startup script
â”œâ”€â”€ .env                  # Environment variables (create this)
â”œâ”€â”€ .gitignore           # Git ignore rules
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ DEPLOYMENT.md        # Deployment guide
â”œâ”€â”€ API.md               # API documentation
â”œâ”€â”€ COMPLIANCE.md        # Compliance overview
â”œâ”€â”€ DEMO_SCRIPT.md       # Sales demo script
â”œâ”€â”€ templates/           # HTML templates
â”‚   â”œâ”€â”€ index.html       # Home page
â”‚   â”œâ”€â”€ dashboard.html   # Dashboard page
â”‚   â”œâ”€â”€ create_project.html
â”‚   â”œâ”€â”€ project_detail.html
â”‚   â”œâ”€â”€ 404.html         # Error pages
â”‚   â””â”€â”€ 500.html
â””â”€â”€ dummy_docs/          # Sample documents
    â””â”€â”€ .gitkeep
```

## ğŸ¯ AI Risk Assessment Logic

The system evaluates projects using advanced AI analysis:

1. **Document Analysis**
   - Complexity scoring and readability assessment
   - Sensitive data detection (PHI, PII, confidential information)
   - Specialized terminology identification

2. **Project Assessment**
   - Deadline analysis with AI-powered predictions
   - Quality risk evaluation based on content and linguist expertise
   - Resource optimization and workload distribution
   - Contextual recommendation generation

3. **Risk Prioritization**
   - Sensitive Data (highest priority)
   - Deadline Management
   - Quality Assurance
   - Resource Allocation
   - Terminology Management

## ğŸ”® Future Enhancements

- **Advanced AI Models**: Integration with specialized translation AI models
- **API Endpoints**: RESTful API for TMS integration
- **Advanced Analytics**: Predictive modeling and trend analysis
- **Multi-language Support**: Interface localization
- **Real-time Notifications**: Email/SMS alerts for high-risk projects
- **Advanced Reporting**: Custom reports and analytics
- **Machine Learning**: Continuous learning from project outcomes

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ Support

For support, email support@gpo-product.com or create an issue in the repository.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**GPO - Empowering LSPs with AI-Driven Project Intelligence** 
